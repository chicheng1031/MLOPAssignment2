{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLOps HW2 Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import dataiku\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import dataiku.core.pandasutils as pdu\n",
    "from dataiku.doctor.preprocessing import PCA\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.width', 3000)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing base data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We apply the preparation that you defined. You should not modify this.\n",
    "preparation_steps = [{'type': 'RoundProcessor', 'params': {'mode': 'ROUND', 'places': 0, 'precision': 0, 'appliesTo': 'SINGLE_COLUMN', 'columns': ['Chance of Admit']}, 'metaType': 'PROCESSOR', 'preview': True, 'disabled': False, 'alwaysShowComment': False}]\n",
    "preparation_output_schema = {'columns': [{'name': 'Serial No.', 'type': 'bigint'}, {'name': 'GRE Score', 'type': 'bigint'}, {'name': 'TOEFL Score', 'type': 'bigint'}, {'name': 'University Rating', 'type': 'bigint'}, {'name': 'CGPA', 'type': 'double'}, {'name': 'Research', 'type': 'bigint'}, {'name': 'Chance of Admit', 'type': 'bigint'}, {'name': 'SOP', 'type': 'double'}, {'name': 'LOR', 'type': 'double'}], 'userModified': False}\n",
    "\n",
    "ml_dataset_handle = dataiku.Dataset('US_graduate_schools_admission_parameters_dataset_joined')\n",
    "ml_dataset_handle.set_preparation_steps(preparation_steps, preparation_output_schema)\n",
    "%time ml_dataset = ml_dataset_handle.get_dataframe(limit = 100000)\n",
    "\n",
    "print ('Base data has %i rows and %i columns' % (ml_dataset.shape[0], ml_dataset.shape[1]))\n",
    "# Five first records\",\n",
    "ml_dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial data management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_dataset = ml_dataset[['SOP', 'University Rating', 'GRE Score', 'CGPA', 'Research', 'Chance of Admit', 'LOR', 'TOEFL Score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# astype('unicode') does not work as expected\n",
    "\n",
    "def coerce_to_unicode(x):\n",
    "    if sys.version_info < (3, 0):\n",
    "        if isinstance(x, str):\n",
    "            return unicode(x,'utf-8')\n",
    "        else:\n",
    "            return unicode(x)\n",
    "    else:\n",
    "        return str(x)\n",
    "\n",
    "\n",
    "categorical_features = []\n",
    "numerical_features = ['SOP', 'University Rating', 'GRE Score', 'CGPA', 'Research', 'LOR', 'TOEFL Score']\n",
    "text_features = []\n",
    "from dataiku.doctor.utils import datetime_to_epoch\n",
    "for feature in categorical_features:\n",
    "    ml_dataset[feature] = ml_dataset[feature].apply(coerce_to_unicode)\n",
    "for feature in text_features:\n",
    "    ml_dataset[feature] = ml_dataset[feature].apply(coerce_to_unicode)\n",
    "for feature in numerical_features:\n",
    "    if ml_dataset[feature].dtype == np.dtype('M8[ns]') or (hasattr(ml_dataset[feature].dtype, 'base') and ml_dataset[feature].dtype.base == np.dtype('M8[ns]')):\n",
    "        ml_dataset[feature] = datetime_to_epoch(ml_dataset[feature])\n",
    "    else:\n",
    "        ml_dataset[feature] = ml_dataset[feature].astype('double')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_map = {'0': 0, '1': 1}\n",
    "ml_dataset['__target__'] = ml_dataset['Chance of Admit'].map(str).map(target_map)\n",
    "del ml_dataset['Chance of Admit']\n",
    "\n",
    "\n",
    "# Remove rows for which the target is unknown.\n",
    "ml_dataset = ml_dataset[~ml_dataset['__target__'].isnull()]\n",
    "\n",
    "ml_dataset['__target__'] = ml_dataset['__target__'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-validation strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = pdu.split_train_valid(ml_dataset, prop=0.8)\n",
    "print ('Train data has %i rows and %i columns' % (train.shape[0], train.shape[1]))\n",
    "print ('Test data has %i rows and %i columns' % (test.shape[0], test.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_rows_when_missing = []\n",
    "impute_when_missing = [{'feature': 'SOP', 'impute_with': 'MEAN'}, {'feature': 'University Rating', 'impute_with': 'MEAN'}, {'feature': 'GRE Score', 'impute_with': 'MEAN'}, {'feature': 'CGPA', 'impute_with': 'MEAN'}, {'feature': 'Research', 'impute_with': 'MEAN'}, {'feature': 'LOR', 'impute_with': 'MEAN'}, {'feature': 'TOEFL Score', 'impute_with': 'MEAN'}]\n",
    "\n",
    "# Features for which we drop rows with missing values\"\n",
    "for feature in drop_rows_when_missing:\n",
    "    train = train[train[feature].notnull()]\n",
    "    test = test[test[feature].notnull()]\n",
    "    print ('Dropped missing records in %s' % feature)\n",
    "\n",
    "# Features for which we impute missing values\"\n",
    "for feature in impute_when_missing:\n",
    "    if feature['impute_with'] == 'MEAN':\n",
    "        v = train[feature['feature']].mean()\n",
    "    elif feature['impute_with'] == 'MEDIAN':\n",
    "        v = train[feature['feature']].median()\n",
    "    elif feature['impute_with'] == 'CREATE_CATEGORY':\n",
    "        v = 'NULL_CATEGORY'\n",
    "    elif feature['impute_with'] == 'MODE':\n",
    "        v = train[feature['feature']].value_counts().index[0]\n",
    "    elif feature['impute_with'] == 'CONSTANT':\n",
    "        v = feature['value']\n",
    "    train[feature['feature']] = train[feature['feature']].fillna(v)\n",
    "    test[feature['feature']] = test[feature['feature']].fillna(v)\n",
    "    print ('Imputed missing values in feature %s with value %s' % (feature['feature'], coerce_to_unicode(v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescale_features = {'SOP': 'AVGSTD', 'University Rating': 'AVGSTD', 'GRE Score': 'AVGSTD', 'CGPA': 'AVGSTD', 'Research': 'AVGSTD', 'LOR': 'AVGSTD', 'TOEFL Score': 'AVGSTD'}\n",
    "for (feature_name, rescale_method) in rescale_features.items():\n",
    "    if rescale_method == 'MINMAX':\n",
    "        _min = train[feature_name].min()\n",
    "        _max = train[feature_name].max()\n",
    "        scale = _max - _min\n",
    "        shift = _min\n",
    "    else:\n",
    "        shift = train[feature_name].mean()\n",
    "        scale = train[feature_name].std()\n",
    "    if scale == 0.:\n",
    "        del train[feature_name]\n",
    "        del test[feature_name]\n",
    "        print ('Feature %s was dropped because it has no variance' % feature_name)\n",
    "    else:\n",
    "        print ('Rescaled %s' % feature_name)\n",
    "        train[feature_name] = (train[feature_name] - shift).astype(np.float64) / scale\n",
    "        test[feature_name] = (test[feature_name] - shift).astype(np.float64) / scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop('__target__', axis=1)\n",
    "X_test = test.drop('__target__', axis=1)\n",
    "\n",
    "y_train = np.array(train['__target__'])\n",
    "y_test = np.array(test['__target__'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(\n",
    "                    random_state = 1337,\n",
    "                    verbose = 0,\n",
    "                    n_estimators = 20,\n",
    "                    learning_rate = 0.36666667,\n",
    "                    loss = 'deviance',\n",
    "                    max_depth = 2\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.class_weight = \"balanced\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time _predictions = clf.predict(X_test)\n",
    "%time _probas = clf.predict_proba(X_test)\n",
    "predictions = pd.Series(data=_predictions, index=X_test.index, name='predicted_value')\n",
    "cols = [\n",
    "    u'probability_of_value_%s' % label\n",
    "    for (_, label) in sorted([(int(target_map[label]), label) for label in target_map])\n",
    "]\n",
    "probabilities = pd.DataFrame(data=_probas, index=X_test.index, columns=cols)\n",
    "\n",
    "# Build scored dataset\n",
    "results_test = X_test.join(predictions, how='left')\n",
    "results_test = results_test.join(probabilities, how='left')\n",
    "results_test = results_test.join(test['__target__'], how='left')\n",
    "results_test = results_test.rename(columns= {'__target__': 'Chance of Admit'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataiku.doctor.utils.metrics import mroc_auc_score\n",
    "y_test_ser = pd.Series(y_test)\n",
    " \n",
    "print ('AUC value:', mroc_auc_score(y_test_ser, _probas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_map = { target_map[label] : label for label in target_map}\n",
    "predictions.map(inv_map)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "modifiedBy": "ziyiz@uchicago.edu",
  "name": "Predicting Chance of Admit in US_graduate_schools_admission_parameters_dataset_joined"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
